{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from helpers import *\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Pandemic Risk\n",
    "\n",
    "Here, we will estimate the expected number of deaths this century from the following types of pandemics:\n",
    "1. Natural pandemics (based on estimates from [Marani et al. 2021](https://doi.org/10.1073/pnas.2105482118))\n",
    "2. Accidental pandemics (based on estimates from [Klotz 2021](https://armscontrolcenter.org/wp-content/uploads/2017/04/LWC-paper-final-version-for-CACNP-website.pdf))\n",
    "3. Deliberate pandemics (based on estimates from [Esvelt 2022](https://dam.gcsp.ch/files/doc/gcsp-geneva-paper-29-22?_gl=1*ieur8b*_ga*MTk1NzA0MTU3My4xNjk2NzcyODA0*_ga_Z66DSTVXTJ*MTY5Njc3MjgwNC4xLjAuMTY5Njc3MjgwNi41OC4wLjA.))\n",
    "\n",
    "Thank you to the Cambridge Biosecurity Group, especially Joshua Blake, for fruitful discussions that informed lots of the estimates here. However, any errors are my own and the estimates I make here are very rough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vars\n",
    "params = Params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will will estimate the expected number of deaths this century i.e. from 2024 to 2100. For simplicity, we'll assume a fixed population of 9.2 billion people over this time period (based on [UN population projections](https://www.worldometers.info/world-population/world-population-projections/)):\n",
    "\n",
    "$\n",
    "\\text{Average population} = \\frac{\\text{Starting population} + \\text{Population in 2100}}{2} = \\frac{8.0 \\text{ billion} + 10.3 \\text{ billion}}{2} = 9.2 \\text{ billion}\n",
    "$\n",
    "\n",
    "For the estimates, we'll be using Monte Carlo simulations. These parameters which are used for multiple of the estimates are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.print_category('Global')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Estimating Natural Pandemic Risk\n",
    "\n",
    "We'll be estimating the expected number of deaths from natural pandemics this century. This analysis will involve three main sections:\n",
    "\n",
    "1. Load data\n",
    "2. Load the GPD model\n",
    "3. Use the GPD model to estimate the expected number of deaths from natural pandemics this century\n",
    "\n",
    "To esimate natural pandemic risk, we'll use the following parameters from [Marani et al.](https://doi.org/10.1073/pnas.2105482118):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.print_category('Natural')\n",
    "\n",
    "num_simulations = params.Global.num_simulations.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load Data\n",
    "\n",
    "[Marani et al.](https://doi.org/10.1073/pnas.2105482118) assembled a dataset of epidemics that have occured since 1500.\n",
    "\n",
    "For their analysis, which we'll replicate next, they only used data from 1600 due to reliability. They also excluded epidemics that were ongoing at the time of writing (eg: AIDS/HIV, malaria, and COVID-19) or were ended by pharmaceuticals (eg: smallpox) which excluded all epidemics after the end of WWII. This is because they likely have a different distribution.\n",
    "\n",
    "The full dataset is visualised below with the time period from 1600 to 1944, that we'll use for subsequent analyses, highlighted in green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marani_xls = params.Natural.dataset.val\n",
    "marani_df, disease_totals = load_and_preprocess_natural_data(marani_xls)\n",
    "color_map = generate_color_map(disease_totals)\n",
    "fig = plot_disease_timeline(marani_df, disease_totals, color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Load the GPD model\n",
    "\n",
    "Epidemic intensity refers to the number of deaths due to an epidemic in a given year. When we plot this intensity against its exceedance probability, it provides insights into the likelihood of an epidemic of a given intensity occuring in a given year. The exceedance probability is the probability that the epidemic intensity will be exceeded in a given year.\n",
    "\n",
    "Marani et al. demonstrated that this relationship between epidemic intensity and exceedance probability is well-described by the Generalized Pareto Distribution (GPD), a family of continuous probability distributions often used to model the tail of the distribution of extreme events.\n",
    "\n",
    "The GPD is defined mathematically defined as:\n",
    "\n",
    "$\n",
    "H(i) = P_0 + (1 - P_0) \\times \\left(1 + \\frac{\\xi \\times (i - \\mu)}{\\sigma}\\right)^{-\\frac{1}{\\xi}}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ H(i) $ is the exceedance probability of the epidemic intensity $ i $.\n",
    "- $ \\mu $ is the threshold parameter.\n",
    "- $ \\sigma $ is the scale parameter.\n",
    "- $ \\xi $ is the shape parameter.\n",
    "- $ P_0 $ is the probability for intensities below the threshold $ \\mu $.\n",
    "\n",
    "The epidemic intensity is plotted against its exceedance probability below, including the GPD using parameter estimates from [Marani et al.](https://doi.org/10.1073/pnas.2105482118). Note: both axes are on a log scale.\n",
    "\n",
    "<!-- #### Understanding Exceedance Probability\n",
    "\n",
    "The exceedance probability of the yearly maximum epidemic intensity, $ H_1(i) $, is given by $ H_1(i) = 1 - P_1(i) $. This value represents the likelihood that an extreme novel epidemic (irrespective of its causative disease) with an intensity equal to or greater than $ i $, will occur anywhere in the world within a year.\n",
    "\n",
    "To put this into perspective, consider an epidemic with an intensity similar to the 1918-1920 \"Spanish flu.\" For this epidemic, with an intensity of $ i = 5.7 $ deaths per thousand per year, the yearly probability of exceedance is represented by $ H_1(i = 5.7 \\text{â€°/year}) $. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Epidemic intensity refers to the number of deaths due to an epidemic in a given year. When we plot this intensity against its exceedance probability, it provides insights into the likelihood of extreme epidemic events. Specifically, the exceedance probability indicates the probability that the epidemic intensity will be exceeded in a given year.\n",
    "\n",
    "Marani et al. demonstrated that this relationship between epidemic intensity and exceedance probability is well-described by the Generalized Pareto Distribution (GPD). The GPD is particularly useful for modeling extreme events, making it a suitable choice for representing extreme epidemic intensities.\n",
    "\n",
    "The Generalized Pareto Distribution (GPD) is mathematically defined as:\n",
    "\n",
    "\n",
    "\n",
    "Marani et al. showed that the when the epidemic intesity, that is the number of deaths per year, is plotted against the exceedance probability, which is the probability that the epidemic intensity will be exceeded in a given year, the data is well described by a generalized Pareto distribution (GPD). The GPD is a probability distribution that is often used to model extreme events. The GPD is defined as:\n",
    "\n",
    "$\n",
    "\\text{GPD}(x) = \\begin{cases}\n",
    "\\frac{1}{\\sigma} \\left(1 + \\frac{\\xi x}{\\sigma} \\right)^{-\\frac{1}{\\xi} - 1} & \\text{if } \\xi \\neq 0 \\\\\n",
    "\\frac{1}{\\sigma} e^{-\\frac{x}{\\sigma}} & \\text{if } \\xi = 0\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "where $\\sigma$ is the scale parameter and $\\xi$ is the shape parameter. The exceedance probability is defined as:\n",
    "\n",
    "$\n",
    "\\text{Exceedance probability} = \\frac{\\text{Number of epidemics with intensity greater than } x}{\\text{Total number of epidemics}}\n",
    "$\n",
    "\n",
    "The GPD is visualised below: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = params.Natural.mu.val\n",
    "sigma = params.Natural.sigma.val\n",
    "xi = params.Natural.xi.val\n",
    "\n",
    "marani_1e_5_df = marani_df[(marani_df[\"Intensity (deaths per thousand/year)\"] > 1e-5) & (marani_df[\"Start Year\"].between(1600, 1944))]\n",
    "# marani_1e_5_df = marani_df[(marani_df[\"Intensity (deaths per thousand/year)\"] > 1e-5) & (marani_df[\"Start Year\"] > 1944)]\n",
    "\n",
    "fig = plot_exceedance_probability(\n",
    "        marani_df=marani_1e_5_df,\n",
    "        plot_gpd=True,\n",
    "        plot_lognorm=False,\n",
    "        mu=mu,\n",
    "        sigma=sigma,\n",
    "        xi=xi\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use the GPD Model to Estimate the Expected Number of Deaths from Natural Pandemics this Century\n",
    "\n",
    "To estimate the yearly expected intensity, I first truncated the GPD at 17.8 deaths per thousand per year, as this is the highest credible reports of deaths for a pandemic, 100 million deaths from 1918 influenza divided by population at the time, divided by the three-year duration, similar to the method used by [Glennerster et al.](https://www.nber.org/system/files/working_papers/w30565/w30565.pdf). I then calculated the intergral of the GPD from 0 to this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = params.Global.population.val\n",
    "max_intensity = params.Natural.max_intensity.val\n",
    "vaccines_multiplier = params.Natural.vaccines_multiplier.val\n",
    "\n",
    "intensities= np.linspace(mu, max_intensity, 1000)\n",
    "# gpd_values = genpareto.sf(intensities - mu, xi, scale=sigma)\n",
    "gpd_values = compute_gpd(intensities, mu, sigma, xi)\n",
    "expected_yearly_intensity = np.trapz(intensities * gpd_values, intensities) * vaccines_multiplier\n",
    "E_natural_deaths_annual = expected_yearly_intensity * (population / 1e3)\n",
    "\n",
    "fig = plot_exceedance_probability(intensities, gpd_values, log_axis=False, title_text=f\"Expected yearly intensity = {E_natural_deaths_annual/1e6:.1f} million deaths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the expected number of natural pandemic deaths this century, I simply multiplied the yearly expected intensity by the number of years remaining this century:\n",
    "\n",
    "$\n",
    "E[\\text{#deliberate_deaths}] = E[\\text{#deliberate_deaths_per_year}] \\times \\text{#years}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_years = params.Global.num_years.val\n",
    "E_natural_deaths = E_natural_deaths_annual * num_years\n",
    "\n",
    "display_text(f\"Expected number of deaths from natural epidemics this century = <strong>{E_natural_deaths/1e6:.1f} million deaths</strong>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "The results of this analysis are similar to those of [Madhav et al.](https://www.cgdev.org/sites/default/files/estimated-future-mortality-pathogens-epidemic-and-pandemic-potential.pdf) who reported an annual expected 2.5 million deaths or **197.6 million deaths** this century. However there are several limitations to this analysis. \n",
    "\n",
    "The limitations of this analysis include:\n",
    "- The estimate may be inaccurate as:\n",
    "    - The GPD may not be a good fit for the data. It is particular hard to determine the probability of extreme events from a small sample size. \n",
    "- The estimate may be an overestimate as: \n",
    "    - Based on visual inspection, the GPD appears to overestimate the probability of extreme events.\n",
    "    - The GPD is fit to data from before the widespread use of antibiotics and vaccines. Although the effect of vaccines has been accounted for approximately, using estimates for COVID-19, the effects of therapeutics and other medical advances have not been accounted for.\n",
    "- The estimate may be an underestimate as:\n",
    "    - It does not account for factors that may increase natural pandemic risk, such as: increasing population density and mobility, climate change, deforestation, and antibiotic resistance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimating Accidental Pandemic Risk\n",
    "\n",
    "We'll be examining the potential risk of a pandemic from the accidental release of viruses from research facilities. This analysis will involve three main sections:\n",
    "\n",
    "1. Probability a single facility in a single year seeds a pandemic\n",
    "2. Expected number of accidental pandemics this century\n",
    "3. Expected number of deaths from accidental pandemics this century"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.print_category('Accidental')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Probability a single facility in a single year seeds a pandemic\n",
    "\n",
    "The probability that a single facility seeds a pandemic in a single year is given by:\n",
    "\n",
    "$\n",
    "P_{\\text{single_pandemic}} = P_{\\text{release}} \\times P_{\\text{seeds_pandemic}}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $P_{\\text{release}}$ is the probability of community release from a single facility in a single year.\n",
    "- $P_{\\text{seeds_pandemic}}$ is the probability that a virus release seeds a pandemic. Since $P_{\\text{seeds_pandemic}}$ is given as a range, we will sample from a uniform distribution between 0.05 and 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_seeds_pandemic_min, P_seeds_pandemic_max = params.Accidental.P_seeds_pandemic.val\n",
    "P_release = params.Accidental.P_release.val\n",
    "accidental_colour = params.Accidental.colour.val\n",
    "\n",
    "P_seeds_pandemic = np.random.uniform(P_seeds_pandemic_min, P_seeds_pandemic_max, num_simulations)\n",
    "P_single_pandemic = P_release * P_seeds_pandemic\n",
    "\n",
    "# Plot the distribution of P_single_pandemic\n",
    "fig = plot_P_single_pandemic_hist(P_single_pandemic, accidental_colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Expected number of accidental pandemics this century\n",
    "\n",
    "The expected number of pandemics seeded by any facility in a $num\\_years$ is given by:\n",
    "\n",
    "$\n",
    "E[\\text{#Pandemics}] = P_{\\text{single_pandemic}} \\times \\text{#years} \\times \\text{#facilities}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $\\text{#years}$ is the number of years in the simulation (typically set to 100 for a century).\n",
    "- $\\text{#facilities}$ is the number of facilities in the world.\n",
    "- $P_{\\text{single_pandemic}}$ is the probability that a single facility seeds a pandemic in a single year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_facilities = params.Accidental.num_facilities.val\n",
    "growth_rate = params.Accidental.growth_rate.val\n",
    "\n",
    "# Store the number of facilities over time\n",
    "facilities_over_time = []\n",
    "\n",
    "for year in range(num_years):\n",
    "    adjusted_facilities = int(num_facilities * (1 + growth_rate) ** year)\n",
    "    facilities_over_time.append(adjusted_facilities)\n",
    "\n",
    "# Convert to a numpy array\n",
    "facilities_over_time = np.array(facilities_over_time)\n",
    "\n",
    "def plot_facilities_over_time(facilities_over_time, accidental_colour, start_year=2023):\n",
    "    years = list(range(start_year, start_year + len(facilities_over_time)))\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter(x=years, y=facilities_over_time, mode='lines', name='Number of Facilities', line=dict(color=accidental_colour))\n",
    "    ])\n",
    "    fig.update_layout(title=\"Number of facilities over time\", xaxis_title=\"Years\", yaxis_title=\"Number of Facilities\")\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "# Example usage\n",
    "fig = plot_facilities_over_time(facilities_over_time, accidental_colour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_accidental_pandemics = []\n",
    "\n",
    "for year in range(num_years):\n",
    "    E_accidental_pandemics_yearly = P_single_pandemic * facilities_over_time[year]\n",
    "    E_accidental_pandemics.append(E_accidental_pandemics_yearly)\n",
    "\n",
    "# Convert to a numpy array\n",
    "E_accidental_pandemics = np.array(E_accidental_pandemics)\n",
    "\n",
    "# Plot the distribution of E_accidental_pandemics\n",
    "E_accidental_pandemics = np.sum(E_accidental_pandemics, axis=0)\n",
    "fig = plot_E_accidental_pandemics_hist(E_accidental_pandemics, accidental_colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Expected number of deaths from accidental pandemics this century\n",
    "\n",
    "For each pandemic, the number of deaths is calculated as:\n",
    "\n",
    "$\n",
    "E[\\text{#Deaths} ]= E[\\text{#Pandemics}] \\times \\text{Population} \\times \\text{Infection Rate} \\times \\text{CFR}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $\\text{Population}$ is the world population at the time of the pandemic.\n",
    "- $\\text{Infection Rate}$ is the infection rate of the pandemic.\n",
    "- $\\text{CFR}$ is the case fatality rate of the pandemic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infection_rate = params.Accidental.infection_rate.val\n",
    "fatality_rate = params.Accidental.fatality_rate.val\n",
    "\n",
    "E_accidental_deaths = E_accidental_pandemics * population * infection_rate * fatality_rate\n",
    "\n",
    "# Plot the distribution of E_accidental_deaths\n",
    "fig = plot_E_accidental_deaths_hist(E_accidental_deaths, accidental_colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "Limitations of this analysis include:\n",
    "- The estimate may be inaccurate as:\n",
    "    - The results are highly dependent on the probabilities of release computed in [Klotz 2020](https://armscontrolcenter.org/wp-content/uploads/2020/03/Quantifying-the-risk-9-17-Supplementary-material-at-end.pdf)\n",
    "- The results may be an overestimate as:\n",
    "    - We are assuming the number of facilities will continue to grow exponentially at the same rate they've grown since 1970\n",
    "- The results may be an underestimate as:\n",
    "    - We are only considering the risk from highly pathogenic avian influenza (HPAI) viruses, and not other types of viruses\n",
    "    - We are only considering the risk from research facilities, and not other sources of accidental release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estimating Deliberate Pandemic Risk\n",
    "\n",
    "To estimate the expected number of deaths from deliberate pandemics this century, we'll perform the following steps:\n",
    "1. Estimate the number of bioterrorists this century<br>\n",
    "    1.1. Using previous terrorist attacks (Method 1)<br>\n",
    "    1.2. Using historical examples of bioterrorists (Method 2)<br>\n",
    "2. Estimating the number of bioterrorists this century (accounting for individuals retraining)\n",
    "3. Estimating the number of deaths (when pandemic blueprints become available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.print_category('Deliberate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtd_xls = params.Deliberate.dataset.val\n",
    "deaths_per_attack = params.Deliberate.deaths_per_attack.val\n",
    "population_us_1995 = params.Deliberate.population_us_1995.val\n",
    "num_indv_capability = params.Deliberate.num_indv_capability.val\n",
    "num_indv_capability_intent_last_century = params.Deliberate.num_indv_capability_intent_last_century.val\n",
    "retrain_indv_multiplier_min, retrain_indv_multiplier_max = params.Deliberate.retrain_indv_multiplier.val\n",
    "deliberate_multiplier_min, deliberate_multiplier_max = params.Deliberate.deliberate_multiplier.val\n",
    "num_years_blueprints_min, num_years_blueprints_max = params.Deliberate.num_years_until_blueprints.val\n",
    "deliberate_colour = params.Deliberate.colour.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Estimating the number of bioterrorists this century\n",
    "We'll use two different methods to estimate the number of individuals who already have the capability and intent i.e. scientists turned bioterrorists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Using previous terrorist attacks (Method 1)\n",
    "\n",
    "$\n",
    "E[\\text{#Bioterrorists}] = \\text{Individuals With Capability} \\times \\text{Fraction of People With Intent}\n",
    "$\n",
    "\n",
    "For the number of individuals with capability, we'll use the number of new individuals who learn to assemble a virus each year from [Esvelt 2022](https://dam.gcsp.ch/files/doc/gcsp-geneva-paper-29-22).\n",
    "\n",
    "For the fraction of these people with intent, we'll estimate this based on previous terrorist incidents in the US. Given the widespread access to firearms in the US we'll assume that any individual who wants to cause mass harm, defined here as killing at least two people, can do so. Specifically, we'll look at the number of terrorist events in the Global Terrorism Database ([GTD](https://www.start.umd.edu/gtd/)) in the US between 1970 and 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "gtd_df = load_and_preprocess_deliberate_data(gtd_xls, deaths_per_attack)\n",
    "num_events = len(gtd_df)\n",
    "\n",
    "# Plot \n",
    "fig = plot_deaths_per_attack_scatter(gtd_df, deaths_per_attack, num_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_invd_intent = num_events / population_us_1995\n",
    "display_text(format_intent_fraction(frac_invd_intent))\n",
    "\n",
    "E_num_bioterrorists_per_year_1 = num_indv_capability * frac_invd_intent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Using historical examples of bioterrorists (Method 2)\n",
    "For this method we'll look at the historical base rate of bioterrorists. Historically terrorists have failed to use bioweapons. In the last century, arguably the individuals who came the closest to releasing an infectious agent were members from the terrorist organisations Aum Shinrikyo and al-Qaeda. Here, we'll assume that they failed due a lack of capability and they would have succeded using biotechnology from this century."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_num_bioterrorists_per_year_2 = num_indv_capability_intent_last_century / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_num_bioterrorists_per_year = np.mean([E_num_bioterrorists_per_year_1, E_num_bioterrorists_per_year_2])\n",
    "display_text(f\"\"\"\n",
    "    Expected number of bioterrorists this century\n",
    "    = (Method 1 + Method 2) / 2\n",
    "    = ({E_num_bioterrorists_per_year_1 * num_years:.1f} + {E_num_bioterrorists_per_year_2 * num_years:.1f}) / 2\n",
    "    = <strong> {E_num_bioterrorists_per_year * num_years:.1f} scientists turned bioterrorists </strong>\n",
    "    \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Estimating the number of bioterrorists this century (accounting for individuals retraining)\n",
    "Here, we'll adjust our estimate to account for terrorists who become bioterrorists using estimate from [Esvelt 2023](https://dam.gcsp.ch/files/doc/securing-civilisation-against-catastrophic-pandemics-gp-31)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account for retraining\n",
    "retrain_indv_multiplier = np.random.uniform(retrain_indv_multiplier_min, retrain_indv_multiplier_max, num_simulations)\n",
    "E_num_bioterrorists_per_year = E_num_bioterrorists_per_year * retrain_indv_multiplier\n",
    "E_num_bioterrorists_this_century = E_num_bioterrorists_per_year * num_years\n",
    "\n",
    "display_text(f\"Expected Number of Bioterrorists this century (accounting for individuals retraining) = <strong> {np.mean(E_num_bioterrorists_this_century):.1f} total bioterrorists </strong>\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Estimating the number of deaths (when pandemic blueprints become available)\n",
    "\n",
    "Here we assume that:\n",
    "1. Blueprints for a pathogen with pandemic potential will become available within the next 50 years\n",
    "2. Blueprints for a pathogen with pandemic potential have an equal probability of becoming available at any point in this 50-year window\n",
    "3. Bioterrorists are unable to cause a deliberate pandemic until such blueprints become available\n",
    "4. That a deliberate pandemic would be 1-10x worse than that caused by a pathogen with 1918 IFR due to factors such as multiple pathogens and/or releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_blueprints_available = np.random.uniform(num_years_blueprints_min, num_years_blueprints_max, num_simulations)\n",
    "deliberate_multiplier = np.random.uniform(deliberate_multiplier_min, deliberate_multiplier_max, num_simulations)\n",
    "E_deliberate_deaths = np.zeros((num_simulations, num_years))\n",
    "for i in range(num_simulations):\n",
    "    for j in range(num_years):\n",
    "        if j >= year_blueprints_available[i]:\n",
    "            E_deliberate_deaths[i, j] = E_num_bioterrorists_per_year[i] * population * infection_rate * fatality_rate * deliberate_multiplier[i]\n",
    "\n",
    "E_deliberate_deaths_avg = (np.mean(E_deliberate_deaths, axis=0))\n",
    "\n",
    "# total_individuals = calculate_individual_capability(params)\n",
    "# fig = plot_capability_growth(params, deliberate_colour)\n",
    "\n",
    "def plot_E_deliberate_deaths_over_time(E_deliberate_deaths_avg, num_years, deliberate_colour, start_year=2023):\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter(x=list(range(start_year, start_year + num_years)), y=E_deliberate_deaths_avg, mode='lines', name='Expected Deaths', line=dict(color=deliberate_colour))\n",
    "    ])\n",
    "    fig.update_layout(title=\"Expected number of deaths from deliberate pandemics over this century\", xaxis_title=\"Years\", yaxis_title=\"Expected Deaths\")\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "fig = plot_E_deliberate_deaths_over_time(E_deliberate_deaths_avg, num_years, deliberate_colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_E_deliberate_deaths_hist(np.sum(E_deliberate_deaths, axis=1), deliberate_colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating intervention cost-effectiveness\n",
    "\n",
    "Here we will compare the cost-effectiveness of different interventions. The cost-effectiveness of an example global health and animal welfare intervention are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.print_category('Interventions')\n",
    "average_dalys_per_life_saved = params.Interventions.average_dalys_per_life_saved.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DNA Synthesis Screening\n",
    "\n",
    "To evaluate the effectiveness of DNA synthesis screening we'll estimate the overall probability of preventing a bioterrorist attack using DNA synthesis screening, which can be decomposed into several contributing factors. Each factor represents a critical step or condition necessary for the screening to be effective. We'll assume that all DNA synthesis providers do effective screening, either voluntarily or due to regulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.print_category('DNA_Screening')\n",
    "\n",
    "P_no_benchtop = params.DNA_Screening.P_no_benchtop.val\n",
    "P_no_academic_approval = params.DNA_Screening.P_no_academic_approval.val\n",
    "P_pathogen_in_database = params.DNA_Screening.P_pathogen_in_database.val\n",
    "P_screening_effective = params.DNA_Screening.P_screening_effective.val\n",
    "dna_screening_cost = params.DNA_Screening.dna_screening_cost.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation for this probability is as follows:\n",
    "\n",
    "$\n",
    "P(\\text{preventing attack with screening}) = P(\\text{no benchtop}) \\times P(\\text{no academic approval}) \\times P(\\text{pathogen in database}) \\times P(\\text{screening effective})\n",
    "$\n",
    "\n",
    "<!-- Where:\n",
    "\n",
    "- $ P(\\text{provider screens}) $ is the probability that the DNA synthesis provider conducts the screening.\n",
    "- $ P(\\text{no academic approval}) $ is the probability that the order does not have academic approval (assuming orders with academic approval bypass the sc$ening).\n",
    "- $ P(\\text{pathogen in database}) $ is the probability that the pathogen is listed in the screening database.\n",
    "- $ P(\\text{screening effective}) $ is the probability that the screening, if conducted, successfully identifies and stops a bioterrorist attack.\n",
    "\n",
    "Gi$n the following estimated probabilities for each factor:\n",
    "\n",
    "- $ P(\\text{provider screens}) = 0.8 $\n",
    "- $ P(\\text{no academic approval}) = 0.75 $\n",
    "- $ P(\\text{pathogen in database}) = 0.5 $\n",
    "- $ P(\\text{screening effective}) = 0.92 $\n",
    "\n",
    "The overall probability of preventing an attack with screening is calculated as:\n",
    "\n",
    "$ P(\\text{preventing attack with screening}) = 0.8 \\times 0.75 \\times 0.5 \\times 0.92 $ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_screening_effective = P_no_benchtop * P_no_academic_approval * P_pathogen_in_database * P_screening_effective\n",
    "\n",
    "display_text(f\"DNA synthesis screening = <strong> {P_screening_effective * 100:.1f}% effective </strong>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assume that screening prevents some percentage of deliberate attacks as defined above. However, we'll also assume that the attacks that are not prevented are the most severe, as the most sophisticated, e.g. better resourced, bioterrorists will be able to evade screening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sophistication_threshold = deliberate_multiplier_max * P_screening_effective\n",
    "E_deliberate_deaths_with_screening = np.zeros(E_deliberate_deaths.shape)\n",
    "\n",
    "for i in range(num_simulations):    \n",
    "    for j in range(num_years):\n",
    "        if j >= year_blueprints_available[i]:\n",
    "            attack_probability = E_num_bioterrorists_per_year[i] * (deliberate_multiplier[i] > sophistication_threshold)\n",
    "            E_deliberate_deaths_with_screening[i, j] = attack_probability * population * infection_rate * fatality_rate * deliberate_multiplier[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the expected deaths over all years\n",
    "E_deliberate_deaths_this_century = np.sum(E_deliberate_deaths, axis=1)\n",
    "E_deliberate_deaths_with_screening_this_century = np.sum(E_deliberate_deaths_with_screening, axis=1)\n",
    "\n",
    "# Plot the expected deaths with and without screening\n",
    "plot_comparative_E_deliberate_deaths_hist(E_deliberate_deaths_this_century, E_deliberate_deaths_with_screening_this_century, deliberate_colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lives_saved_with_screening = int(np.mean(E_deliberate_deaths_this_century - E_deliberate_deaths_with_screening_this_century))\n",
    "dalys_saved_with_screening = lives_saved_with_screening * average_dalys_per_life_saved\n",
    "cost_in_thousands = dna_screening_cost / 1000\n",
    "cost_effectiveness = dalys_saved_with_screening / cost_in_thousands\n",
    "\n",
    "display_text(f\"Cost-effectiveness of DNA synthesis screening = <strong> {cost_effectiveness:,.0f} DALYs / $1000 </strong>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metagenomic Sequencing\n",
    "\n",
    "To evaluate the cost-effectiveness of metagenomic sequencing we'll use estimates for the [ThreatNet](https://pubmed.ncbi.nlm.nih.gov/37367195/) system for early oubtreak detection which relies on metagenomic sequencing of clinical samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.print_category('Sequencing')\n",
    "\n",
    "P_containment = params.Sequencing.P_containment.val\n",
    "threatnet_cost_min, threatnet_cost_max = params.Sequencing.threatnet_cost.val\n",
    "us_pop_frac_global = params.Sequencing.us_pop_frac_global.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to quantify the benefits of early outbreak detection as it is not a direct intervention but rather a tool that can be used to inform interventions. However, we'll assume that the main benefit of early outbreak detection is that it allows interventions such as contact tracing to be implemented earlier with the potential to contain the outbreak before it becomes a pandemic. For this, we'll rely on modelling estimates from [Hellewell et al. 2020](https://www.thelancet.com/journals/langlo/article/PIIS2214-109X(20)30074-7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_pandemic_deaths = E_natural_deaths + np.mean(E_accidental_deaths) + np.mean(E_deliberate_deaths_this_century)\n",
    "\n",
    "lives_saved_with_sequencing = E_pandemic_deaths * P_containment\n",
    "dalys_saved_with_sequencing = lives_saved_with_sequencing * average_dalys_per_life_saved + population * 0.3 * 1/52 * num_years\n",
    "\n",
    "display_text(f\"Expected number of deaths from pandemics this century = <strong> {E_pandemic_deaths:,.0f} </strong>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we estimate the cost of global sequencing by considering the ThreatNet cost and adjusting for the global population and the cost of running the system until the end of the century."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threatnet_cost = np.random.uniform(threatnet_cost_min, threatnet_cost_max, num_simulations)\n",
    "sequencing_cost = threatnet_cost * 1 / us_pop_frac_global * num_years\n",
    "\n",
    "sequencing_cost_in_thousands = sequencing_cost / 1000\n",
    "\n",
    "display_text(f\"Cost of global sequencing = <strong> ${np.mean(sequencing_cost):,.0f} </strong>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the cost-effectiveness of metagenomic sequencing in terms of DALYs saved per $1000 spent. It's possible that the cost of metagenomic sequencing will decrease in the coming decades (e.g. ~10x), see [Sequencing Roadmap](http://sequencing-roadmap.org/). Also, the primary benefit of metagenomic sequencing may be preventing subtle biothreats ([Gopal et al. 2023](https://dam.gcsp.ch/files/doc/securing-civilisation-against-catastrophic-pandemics-gp-31)) and longter-term benefits which are not accounted for here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_effectiveness = dalys_saved_with_sequencing / sequencing_cost_in_thousands\n",
    "\n",
    "display_text(f\"Cost-effectiveness of metagenomic sequencing = <strong> {np.mean(cost_effectiveness):,.0f} DALY / $1000 </strong>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Broad-spectrum vaccines\n",
    "Here we'll estimate the cost-effectiveness of pan-coronavirus and pan-influenza vaccines.\n",
    "\n",
    "We'll assume that a 10x increase in current funding for both pan-coronavirus and pan-influenza vaccines will accelerate the development of both broad-spectrum vaccine by 5 years. I define current funding here as the single largest investment in broad-spectrum vaccines I could find, which is CEPI's $200M investment in pan-coronavirus vaccines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.print_category('Broad_Vaccines')\n",
    "\n",
    "additional_vaccine_years = params.Broad_Vaccines.additional_vaccine_years.val\n",
    "covid_excess_deaths = params.Broad_Vaccines.covid_excess_deaths.val\n",
    "time_to_update_vaccine_min, time_to_update_vaccine_max = params.Broad_Vaccines.time_to_update_vaccine.val\n",
    "current_flu_vaccine_effectiveness_min, current_flu_vaccine_effectiveness_max = params.Broad_Vaccines.current_flu_vaccine_effectiveness.val\n",
    "broad_vaccine_effectiveness_min, broad_vaccine_effectiveness_max = params.Broad_Vaccines.broad_vaccine_effectiveness.val\n",
    "annual_global_flu_deaths_min, annual_global_flu_deaths_max = params.Broad_Vaccines.annual_global_flu_deaths.val\n",
    "broad_cov_research_funding = params.Broad_Vaccines.broad_cov_research_funding.val\n",
    "dalys_lost_per_seasonal_flu_death = params.Broad_Vaccines.dalys_lost_per_seasonal_flu_death.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll quantify the benefits for:\n",
    "1. **Coronavirus and influenza pandemics:** estimating the lives saved due to the immediate availability of vaccines, reducing the impact at the onset of pandemics.\n",
    "2. **Seasonal influenza epidemics:** calculating the additional lives saved by having a vaccine that is more effective than current seasonal influenza vaccines, as it is antigneically matched to the circulating strain in all flu seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract flu-related data from Marani dataset\n",
    "flu_data = marani_1e_5_df[marani_1e_5_df[\"Disease\"] == \"Influenza\"]\n",
    "total_flu_deaths = flu_data[\"# deaths (raw)\"].sum().astype(int)\n",
    "\n",
    "# Combine COVID-19 and influenza deaths\n",
    "combined_flu_covid_deaths = covid_excess_deaths + total_flu_deaths\n",
    "\n",
    "# Calculate the fraction of deaths due to flu and COVID-19\n",
    "fraction_flu_covid_deaths = combined_flu_covid_deaths / (E_natural_deaths + covid_excess_deaths)\n",
    "\n",
    "# Estimate the expected number of deaths from natural coronavirus and influenza epidemics\n",
    "expected_flu_covid_deaths = fraction_flu_covid_deaths * E_natural_deaths_annual\n",
    "\n",
    "# Average duration of epidemics from the dataset\n",
    "average_epidemic_duration = flu_data[\"Duration\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays to store the results for each year\n",
    "lives_saved_seasonal = np.zeros((additional_vaccine_years, num_simulations))\n",
    "lives_saved_pandemic = np.zeros((additional_vaccine_years, num_simulations))\n",
    "\n",
    "for year in range(additional_vaccine_years):\n",
    "    # Randomly sample vaccine effectiveness and time to update vaccine for this year\n",
    "    current_flu_vaccine_effectiveness = np.random.uniform(current_flu_vaccine_effectiveness_min, current_flu_vaccine_effectiveness_max, num_simulations)\n",
    "    broad_vaccine_effectiveness = np.random.uniform(broad_vaccine_effectiveness_min, broad_vaccine_effectiveness_max, num_simulations)\n",
    "    time_to_update_vaccine = np.random.uniform(time_to_update_vaccine_min, time_to_update_vaccine_max, num_simulations)\n",
    "\n",
    "    # Estimate annual global flu deaths for this year\n",
    "    annual_global_flu_deaths = estimate_deaths_vectorized(current_flu_vaccine_effectiveness, annual_global_flu_deaths_min, annual_global_flu_deaths_max)\n",
    "\n",
    "    # Compute lives saved by broad-spectrum vaccine availability and improved seasonal vaccine effectiveness\n",
    "    time_saved_fraction = time_to_update_vaccine / average_epidemic_duration\n",
    "    lives_saved_immediate_vaccine = expected_flu_covid_deaths * time_saved_fraction * (1 - vaccines_multiplier)\n",
    "    additional_lives_saved = annual_global_flu_deaths * ((broad_vaccine_effectiveness - current_flu_vaccine_effectiveness) / current_flu_vaccine_effectiveness)\n",
    "\n",
    "    # Store the lives saved for seasonal and pandemic vaccines separately\n",
    "    lives_saved_seasonal[year] = additional_lives_saved\n",
    "    lives_saved_pandemic[year] = lives_saved_immediate_vaccine\n",
    "\n",
    "# Aggregate the lives saved over all years\n",
    "total_lives_saved_seasonal = np.sum(lives_saved_seasonal, axis=0)\n",
    "total_lives_saved_pandemic = np.sum(lives_saved_pandemic, axis=0)\n",
    "\n",
    "# Plot the results\n",
    "fig = plot_lives_saved_comparison(total_lives_saved_seasonal, total_lives_saved_pandemic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the development cost for broad-spectrum vaccines, we'll consider CEPI's $200M investment in a pan-coronavirus vaccine as a reference (this is largest investment in broad vaccines that I could find). We'll assume that a 20x increase in this investment covers the development of both pan-coronavirus and pan-influenza vaccines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated cost for developing and implementing broad-spectrum vaccines\n",
    "estimated_vaccine_cost = broad_cov_research_funding * 2 * 10  # 10x funding increase assumption\n",
    "estimated_vaccine_cost_thousands = estimated_vaccine_cost / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert total lives saved to DALYs\n",
    "dalys = total_lives_saved_seasonal * dalys_lost_per_seasonal_flu_death + total_lives_saved_pandemic * average_dalys_per_life_saved\n",
    "\n",
    "# Cost-Effectiveness Calculation\n",
    "cost_effectiveness = np.mean(dalys / estimated_vaccine_cost_thousands)\n",
    "\n",
    "# Display the cost-effectiveness result\n",
    "display_text(f\"Cost-effectiveness of broad-spectrum vaccines = <strong> {cost_effectiveness:,.0f} DALY / $1000 </strong>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "4955dedc2d00847a5d8ce35d0b08f51a09c63081b880cfd982b13da27f1123ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
